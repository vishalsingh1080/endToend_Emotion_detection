{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-emo_detect_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishalsingh1080/endToend_Emotion_detection/blob/main/TF_emo_detect_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqcEHWEj-Ort"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense,Conv2D,Dropout,BatchNormalization,MaxPool2D\n",
        "from tensorflow.keras.activations import relu\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report\n",
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5qx_P71-0sX",
        "outputId": "b54b561e-c23b-4197-8008-351adf357096"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkfNgfFWJp5A",
        "outputId": "86de7356-5d9c-41c8-cc2a-f2b23126756c"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name) "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFTNtLXJB-q9"
      },
      "source": [
        "!unzip -q '/content/gdrive/My Drive/emotion_detection/FER2013.zip' -d FER2013\n",
        "!unzip -q '/content/gdrive/My Drive/emotion_detection/private_test.zip' -d private_test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFCpIi_-46an"
      },
      "source": [
        "0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNA8uY6HG2Vu",
        "outputId": "2c99532c-6150-49a9-e40a-7c5b978f9712"
      },
      "source": [
        "img = cv2.imread('/content/FER2013/train/angry/Training_10118481.jpg')\n",
        "img.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48, 48, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTm3bWQeHEo5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "ad874e21-7399-4c3d-fb38-ed3ed64ca462"
      },
      "source": [
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3482374d90>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuCOdreWjPJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e9a358f-8f44-4b7c-82fc-6a59256fda96"
      },
      "source": [
        "img = cv2.imread('/content/private_test/disgust/disgust-000034.png')\n",
        "img.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48, 48, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5yV4A0ojya6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "d01c85cd-fbb1-4a9e-96a9-d38af13c8450"
      },
      "source": [
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3481e560d0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCmYBsxb1xK4"
      },
      "source": [
        "# initialize the training data augmentation object\n",
        "trainAug = ImageDataGenerator( rescale=1./255,\n",
        "                            rotation_range=20,\n",
        "                            width_shift_range=0.2,\n",
        "                            height_shift_range=0.2,\n",
        "                            horizontal_flip=True)\n",
        "# initialize the validation/testing data augmentation object \n",
        "valAug = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKHRbagT2Gv_",
        "outputId": "2ae3f959-fcde-4045-e4c0-7b10e357279a"
      },
      "source": [
        "# initialize the training generator\n",
        "trainGen = trainAug.flow_from_directory(\n",
        "\t'/content/FER2013/train',\n",
        "  class_mode=\"categorical\",\n",
        "\ttarget_size=(48,48),\n",
        "\tcolor_mode=\"grayscale\",\n",
        "\tshuffle=True,\n",
        "\tbatch_size=64)\n",
        "# initialize the validation generator\n",
        "valGen = valAug.flow_from_directory(\n",
        "\t'/content/FER2013/test',\n",
        "  class_mode=\"categorical\",\n",
        "\ttarget_size=(48,48),\n",
        "\tcolor_mode=\"grayscale\",\n",
        "\tshuffle=False,\n",
        "\tbatch_size=64)\n",
        "# initialize the testing generator\n",
        "testGen = valAug.flow_from_directory(\n",
        "\t'/content/private_test',\n",
        "  class_mode=\"categorical\",\n",
        "\ttarget_size=(48,48),\n",
        "\tcolor_mode=\"grayscale\",\n",
        "\tshuffle=False,\n",
        "\tbatch_size=64)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28709 images belonging to 7 classes.\n",
            "Found 7178 images belonging to 7 classes.\n",
            "Found 3589 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdxYmOBcmQll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2274987-2e5a-4654-82e6-850e61f78924"
      },
      "source": [
        "no_train_files =  sum(len(files) for _, _, files in os.walk(r'/content/FER2013/train'))\n",
        "no_val_files = sum(len(files) for _, _, files in os.walk(r'/content/FER2013/test'))\n",
        "no_test_files = sum(len(files) for _, _, files in os.walk(r'/content/private_test'))\n",
        "\n",
        "print(no_train_files,no_val_files,no_test_files)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28709 7178 3589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NWQo1mhyMJe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b19f9cd-295b-487b-9893-73bcf77cf05b"
      },
      "source": [
        "test = next(trainGen)\n",
        "test[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 48, 48, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PY8jX7rfCJE-",
        "outputId": "c6ab5b21-3cfe-40b8-e80c-fe7e1a763b84"
      },
      "source": [
        "valGen.class_indices"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'angry': 0,\n",
              " 'disgust': 1,\n",
              " 'fear': 2,\n",
              " 'happy': 3,\n",
              " 'neutral': 4,\n",
              " 'sad': 5,\n",
              " 'surprise': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN4Fq8TeT8ii"
      },
      "source": [
        "# path_to_downloaded_file = tf.keras.utils.get_file('rcmalli_vggface_tf_vgg16.h5','https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_vgg16.h5')\n",
        "\n",
        "# baseModel = VGG16(input_shape=(128, 128,3),include_top = False,weights='/root/.keras/datasets/rcmalli_vggface_tf_vgg16.h5',)\n",
        "# # baseModel.summary()\n",
        "# baseModel.layers[-1].output \n",
        "\n",
        "# base_output = baseModel.layers[-1].output \n",
        "# # new head for fine-tuning\n",
        "# x = Flatten(name='flatten')(base_output)\n",
        "# x = Dropout(0.5)(x)\n",
        "# x = Dense(4096, activation='relu', name='fc6')(x)\n",
        "# x = Dropout(0.5)(x)\n",
        "# x = Dense(1024, activation='relu', name='fc7')(x)\n",
        "# out = Dense(7, activation='softmax', name='classifier')(x)\n",
        "\n",
        "# model = Model(baseModel.input, out)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPPCWBDhauS7"
      },
      "source": [
        "def conv2d_custom_pad(input,pad,filters,kernel_size):\n",
        "    \n",
        "    x = tf.pad(input, ((0, 0), (int(pad),int(pad)), (int(pad),int(pad)),(0, 0)), \"CONSTANT\")\n",
        "    x = Conv2D(filters=filters,kernel_size=kernel_size)(x)\n",
        "    return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIpg1KCBB5HA"
      },
      "source": [
        "def VGG16(drop=0.2):\n",
        "       \n",
        "      input = tf.keras.Input(shape=(48,48,1))\n",
        "    \n",
        "      conv1a = conv2d_custom_pad(input,pad=1,filters=64,kernel_size=3)\n",
        "      bn1a = BatchNormalization()(conv1a)\n",
        "      x = relu(bn1a)\n",
        "      \n",
        "      conv1b = conv2d_custom_pad(x,pad=1,filters=64,kernel_size=3)\n",
        "      bn1b = BatchNormalization()(conv1b)\n",
        "      x = relu(bn1b)\n",
        "      x = MaxPool2D(2,strides=2)(x)\n",
        "      \n",
        "      conv2a = conv2d_custom_pad(x,pad=1,filters=128,kernel_size=3)\n",
        "      bn2a = BatchNormalization()(conv2a)\n",
        "      x = relu(bn2a)\n",
        "      \n",
        "      conv2b = conv2d_custom_pad(x,pad=1,filters=128,kernel_size=3)\n",
        "      bn2b = BatchNormalization()(conv2b)\n",
        "      x = relu(bn2b)\n",
        "      x = MaxPool2D(2,strides=2)(x)\n",
        "      \n",
        "      conv3a = conv2d_custom_pad(x,pad=1,filters=256,kernel_size=3)\n",
        "      bn3a = BatchNormalization()(conv3a)\n",
        "      x = relu(bn3a)\n",
        "      \n",
        "      conv3b = conv2d_custom_pad(x,pad=1,filters=256,kernel_size=3)\n",
        "      bn3b = BatchNormalization()(conv3b)\n",
        "      x = relu(bn3b)\n",
        "      x = MaxPool2D(2,strides=2)(x)\n",
        "      \n",
        "      conv4a = conv2d_custom_pad(x,pad=1,filters=512,kernel_size=3)\n",
        "      bn4a = BatchNormalization()(conv4a)\n",
        "      x = relu(bn4a)\n",
        "      \n",
        "      conv4b = conv2d_custom_pad(x,pad=1,filters=512,kernel_size=3)\n",
        "      bn4b = BatchNormalization()(conv4b)\n",
        "      x = relu(bn4b)\n",
        "      x = MaxPool2D(2,strides=2)(x)\n",
        "      \n",
        "      x = layers.Flatten()(x)\n",
        "      \n",
        "      x = Dense(4096)(x)\n",
        "      x = Dropout(drop)(x)\n",
        "      x = relu(x)\n",
        "      \n",
        "      x = Dense(4096)(x)\n",
        "      x = Dropout(drop)(x)\n",
        "      x = relu(x)\n",
        "      \n",
        "      x = Dense(7)(x)\n",
        "      output = layers.Activation('softmax', dtype='float32', name='predictions')(x)\n",
        "\n",
        "      model = tf.keras.Model(input,output)\n",
        "      return model   "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycfLGFgqCgVu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "470f2039-8b4d-47a9-cd34-b8a366f68a2c"
      },
      "source": [
        "model = VGG16()\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 48, 48, 1)]       0         \n",
            "_________________________________________________________________\n",
            "tf.compat.v1.pad (TFOpLambda (None, 50, 50, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 48, 48, 64)        640       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 48, 48, 64)        256       \n",
            "_________________________________________________________________\n",
            "tf.nn.relu (TFOpLambda)      (None, 48, 48, 64)        0         \n",
            "_________________________________________________________________\n",
            "tf.compat.v1.pad_1 (TFOpLamb (None, 50, 50, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 48, 48, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 48, 48, 64)        256       \n",
            "_________________________________________________________________\n",
            "tf.nn.relu_1 (TFOpLambda)    (None, 48, 48, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "tf.compat.v1.pad_2 (TFOpLamb (None, 26, 26, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 128)       512       \n",
            "_________________________________________________________________\n",
            "tf.nn.relu_2 (TFOpLambda)    (None, 24, 24, 128)       0         \n",
            "_________________________________________________________________\n",
            "tf.compat.v1.pad_3 (TFOpLamb (None, 26, 26, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 24, 24, 128)       512       \n",
            "_________________________________________________________________\n",
            "tf.nn.relu_3 (TFOpLambda)    (None, 24, 24, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "tf.compat.v1.pad_4 (TFOpLamb (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 12, 12, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 12, 12, 256)       1024      \n",
            "_________________________________________________________________\n",
            "tf.nn.relu_4 (TFOpLambda)    (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "tf.compat.v1.pad_5 (TFOpLamb (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 12, 12, 256)       1024      \n",
            "_________________________________________________________________\n",
            "tf.nn.relu_5 (TFOpLambda)    (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "tf.compat.v1.pad_6 (TFOpLamb (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 6, 6, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 6, 6, 512)         2048      \n",
            "_________________________________________________________________\n",
            "tf.nn.relu_6 (TFOpLambda)    (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "tf.compat.v1.pad_7 (TFOpLamb (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 6, 6, 512)         2048      \n",
            "_________________________________________________________________\n",
            "tf.nn.relu_7 (TFOpLambda)    (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              18878464  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "tf.nn.relu_8 (TFOpLambda)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "tf.nn.relu_9 (TFOpLambda)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 7)                 28679     \n",
            "_________________________________________________________________\n",
            "predictions (Activation)     (None, 7)                 0         \n",
            "=================================================================\n",
            "Total params: 40,380,359\n",
            "Trainable params: 40,376,519\n",
            "Non-trainable params: 3,840\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fealCfFn9Zls"
      },
      "source": [
        "checkpoint_path = '/content/gdrive/My Drive/emotion_detection/checkpoints/cp.ckpt'\n",
        "\n",
        "model_save = ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,save_best_only=True,monitor='val_accuracy')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBSlhMHBHzTG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44188f96-d7b3-424d-fb23-ce3195ae748d"
      },
      "source": [
        "# early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "sgd = SGD(lr=0.01, momentum=0.9, decay=0.0001, nesterov=True)\n",
        "rlrop = ReduceLROnPlateau(monitor='val_accuracy',mode='max',factor=0.75, patience=5, min_lr=0.00001, verbose=1)\n",
        "\n",
        "model.compile(loss=CategoricalCrossentropy(), optimizer=sgd,metrics=[\"accuracy\"])\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "      H = model.fit(\n",
        "        x=trainGen,\n",
        "        steps_per_epoch=no_train_files// 64,\n",
        "        validation_data=valGen,\n",
        "        validation_steps=no_val_files// 64,\n",
        "        epochs=300,\n",
        "        callbacks = [model_save,rlrop],\n",
        "        use_multiprocessing=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "448/448 [==============================] - 92s 137ms/step - loss: 1.8910 - accuracy: 0.2444 - val_loss: 1.8269 - val_accuracy: 0.2469\n",
            "Epoch 2/300\n",
            "448/448 [==============================] - 60s 135ms/step - loss: 1.7797 - accuracy: 0.2599 - val_loss: 1.8089 - val_accuracy: 0.2536\n",
            "Epoch 3/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 1.7180 - accuracy: 0.2932 - val_loss: 1.7395 - val_accuracy: 0.2699\n",
            "Epoch 4/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 1.5695 - accuracy: 0.3769 - val_loss: 1.5563 - val_accuracy: 0.4012\n",
            "Epoch 5/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 1.4374 - accuracy: 0.4385 - val_loss: 1.3358 - val_accuracy: 0.4835\n",
            "Epoch 6/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 1.3425 - accuracy: 0.4858 - val_loss: 1.2592 - val_accuracy: 0.5135\n",
            "Epoch 7/300\n",
            "448/448 [==============================] - 60s 133ms/step - loss: 1.2683 - accuracy: 0.5144 - val_loss: 1.3916 - val_accuracy: 0.4643\n",
            "Epoch 8/300\n",
            "448/448 [==============================] - 60s 135ms/step - loss: 1.2103 - accuracy: 0.5402 - val_loss: 1.3276 - val_accuracy: 0.4937\n",
            "Epoch 9/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 1.1742 - accuracy: 0.5514 - val_loss: 1.3641 - val_accuracy: 0.5022\n",
            "Epoch 10/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 1.1421 - accuracy: 0.5631 - val_loss: 1.2367 - val_accuracy: 0.5407\n",
            "Epoch 11/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 1.1116 - accuracy: 0.5791 - val_loss: 1.1745 - val_accuracy: 0.5515\n",
            "Epoch 12/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 1.0806 - accuracy: 0.5881 - val_loss: 1.2074 - val_accuracy: 0.5299\n",
            "Epoch 13/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 1.0612 - accuracy: 0.5978 - val_loss: 1.0758 - val_accuracy: 0.5911\n",
            "Epoch 14/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 1.0473 - accuracy: 0.6050 - val_loss: 1.0362 - val_accuracy: 0.6074\n",
            "Epoch 15/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 1.0287 - accuracy: 0.6121 - val_loss: 1.0792 - val_accuracy: 0.5964\n",
            "Epoch 16/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 1.0131 - accuracy: 0.6156 - val_loss: 1.0444 - val_accuracy: 0.6052\n",
            "Epoch 17/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.9947 - accuracy: 0.6244 - val_loss: 1.0300 - val_accuracy: 0.6080\n",
            "Epoch 18/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.9814 - accuracy: 0.6301 - val_loss: 1.0290 - val_accuracy: 0.6104\n",
            "Epoch 19/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.9682 - accuracy: 0.6334 - val_loss: 1.0190 - val_accuracy: 0.6217\n",
            "Epoch 20/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.9535 - accuracy: 0.6417 - val_loss: 1.0390 - val_accuracy: 0.6164\n",
            "Epoch 21/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.9423 - accuracy: 0.6435 - val_loss: 0.9785 - val_accuracy: 0.6316\n",
            "Epoch 22/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.9370 - accuracy: 0.6479 - val_loss: 0.9812 - val_accuracy: 0.6343\n",
            "Epoch 23/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.9263 - accuracy: 0.6514 - val_loss: 1.0665 - val_accuracy: 0.6110\n",
            "Epoch 24/300\n",
            "448/448 [==============================] - 60s 135ms/step - loss: 0.9111 - accuracy: 0.6551 - val_loss: 0.9446 - val_accuracy: 0.6493\n",
            "Epoch 25/300\n",
            "448/448 [==============================] - 60s 135ms/step - loss: 0.8988 - accuracy: 0.6633 - val_loss: 0.9807 - val_accuracy: 0.6307\n",
            "Epoch 26/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.8951 - accuracy: 0.6618 - val_loss: 0.9748 - val_accuracy: 0.6383\n",
            "Epoch 27/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.8813 - accuracy: 0.6697 - val_loss: 0.9818 - val_accuracy: 0.6417\n",
            "Epoch 28/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.8750 - accuracy: 0.6749 - val_loss: 1.0703 - val_accuracy: 0.6046\n",
            "Epoch 29/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.8677 - accuracy: 0.6745 - val_loss: 0.9581 - val_accuracy: 0.6380\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
            "Epoch 30/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.8378 - accuracy: 0.6853 - val_loss: 1.0161 - val_accuracy: 0.6292\n",
            "Epoch 31/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.8251 - accuracy: 0.6884 - val_loss: 0.9583 - val_accuracy: 0.6479\n",
            "Epoch 32/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.8199 - accuracy: 0.6918 - val_loss: 0.9816 - val_accuracy: 0.6360\n",
            "Epoch 33/300\n",
            "448/448 [==============================] - 60s 135ms/step - loss: 0.8082 - accuracy: 0.6958 - val_loss: 1.0635 - val_accuracy: 0.6166\n",
            "Epoch 34/300\n",
            "448/448 [==============================] - 60s 135ms/step - loss: 0.8061 - accuracy: 0.6967 - val_loss: 0.9540 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
            "Epoch 35/300\n",
            "448/448 [==============================] - 61s 136ms/step - loss: 0.7728 - accuracy: 0.7117 - val_loss: 0.9237 - val_accuracy: 0.6636\n",
            "Epoch 36/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.7711 - accuracy: 0.7108 - val_loss: 0.9424 - val_accuracy: 0.6462\n",
            "Epoch 37/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.7621 - accuracy: 0.7171 - val_loss: 0.9805 - val_accuracy: 0.6455\n",
            "Epoch 38/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.7588 - accuracy: 0.7173 - val_loss: 0.9219 - val_accuracy: 0.6646\n",
            "Epoch 39/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.7439 - accuracy: 0.7199 - val_loss: 0.9403 - val_accuracy: 0.6565\n",
            "Epoch 40/300\n",
            "448/448 [==============================] - 60s 135ms/step - loss: 0.7401 - accuracy: 0.7232 - val_loss: 0.9946 - val_accuracy: 0.6398\n",
            "Epoch 41/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.7332 - accuracy: 0.7264 - val_loss: 0.9385 - val_accuracy: 0.6676\n",
            "Epoch 42/300\n",
            "448/448 [==============================] - 60s 135ms/step - loss: 0.7337 - accuracy: 0.7255 - val_loss: 0.9869 - val_accuracy: 0.6466\n",
            "Epoch 43/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.7287 - accuracy: 0.7272 - val_loss: 0.9831 - val_accuracy: 0.6476\n",
            "Epoch 44/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.7199 - accuracy: 0.7312 - val_loss: 0.9352 - val_accuracy: 0.6611\n",
            "Epoch 45/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.7140 - accuracy: 0.7324 - val_loss: 1.1857 - val_accuracy: 0.6053\n",
            "Epoch 46/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.7134 - accuracy: 0.7350 - val_loss: 1.0495 - val_accuracy: 0.6335\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.004218749818392098.\n",
            "Epoch 47/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.6867 - accuracy: 0.7452 - val_loss: 0.9370 - val_accuracy: 0.6677\n",
            "Epoch 48/300\n",
            "448/448 [==============================] - 60s 135ms/step - loss: 0.6814 - accuracy: 0.7466 - val_loss: 1.0045 - val_accuracy: 0.6561\n",
            "Epoch 49/300\n",
            "448/448 [==============================] - 60s 135ms/step - loss: 0.6756 - accuracy: 0.7479 - val_loss: 0.9398 - val_accuracy: 0.6692\n",
            "Epoch 50/300\n",
            "448/448 [==============================] - 60s 135ms/step - loss: 0.6747 - accuracy: 0.7495 - val_loss: 0.9390 - val_accuracy: 0.6727\n",
            "Epoch 51/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.6611 - accuracy: 0.7525 - val_loss: 0.9377 - val_accuracy: 0.6765\n",
            "Epoch 52/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.6560 - accuracy: 0.7544 - val_loss: 0.9293 - val_accuracy: 0.6814\n",
            "Epoch 53/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.6538 - accuracy: 0.7541 - val_loss: 1.0066 - val_accuracy: 0.6634\n",
            "Epoch 54/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.6529 - accuracy: 0.7557 - val_loss: 1.0015 - val_accuracy: 0.6569\n",
            "Epoch 55/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.6484 - accuracy: 0.7601 - val_loss: 0.9363 - val_accuracy: 0.6758\n",
            "Epoch 56/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.6411 - accuracy: 0.7612 - val_loss: 1.0057 - val_accuracy: 0.6459\n",
            "Epoch 57/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.6345 - accuracy: 0.7623 - val_loss: 0.9764 - val_accuracy: 0.6724\n",
            "\n",
            "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.003164062276482582.\n",
            "Epoch 58/300\n",
            "448/448 [==============================] - 60s 133ms/step - loss: 0.6179 - accuracy: 0.7704 - val_loss: 0.9969 - val_accuracy: 0.6625\n",
            "Epoch 59/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.6109 - accuracy: 0.7727 - val_loss: 0.9829 - val_accuracy: 0.6731\n",
            "Epoch 60/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.6144 - accuracy: 0.7727 - val_loss: 0.9830 - val_accuracy: 0.6628\n",
            "Epoch 61/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.6084 - accuracy: 0.7731 - val_loss: 0.9479 - val_accuracy: 0.6744\n",
            "Epoch 62/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.6003 - accuracy: 0.7741 - val_loss: 1.0036 - val_accuracy: 0.6650\n",
            "\n",
            "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0023730467073619366.\n",
            "Epoch 63/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.5881 - accuracy: 0.7794 - val_loss: 1.0052 - val_accuracy: 0.6653\n",
            "Epoch 64/300\n",
            "448/448 [==============================] - 60s 135ms/step - loss: 0.5853 - accuracy: 0.7834 - val_loss: 0.9683 - val_accuracy: 0.6742\n",
            "Epoch 65/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.5767 - accuracy: 0.7873 - val_loss: 0.9874 - val_accuracy: 0.6713\n",
            "Epoch 66/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.5747 - accuracy: 0.7856 - val_loss: 0.9537 - val_accuracy: 0.6840\n",
            "Epoch 67/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.5708 - accuracy: 0.7862 - val_loss: 1.0879 - val_accuracy: 0.6558\n",
            "Epoch 68/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.5663 - accuracy: 0.7891 - val_loss: 0.9928 - val_accuracy: 0.6699\n",
            "Epoch 69/300\n",
            "448/448 [==============================] - 60s 135ms/step - loss: 0.5681 - accuracy: 0.7894 - val_loss: 0.9896 - val_accuracy: 0.6801\n",
            "Epoch 70/300\n",
            "448/448 [==============================] - 60s 135ms/step - loss: 0.5576 - accuracy: 0.7918 - val_loss: 1.0241 - val_accuracy: 0.6738\n",
            "Epoch 71/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.5566 - accuracy: 0.7931 - val_loss: 1.0419 - val_accuracy: 0.6703\n",
            "\n",
            "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.0017797850305214524.\n",
            "Epoch 72/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.5483 - accuracy: 0.7959 - val_loss: 0.9829 - val_accuracy: 0.6729\n",
            "Epoch 73/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.5441 - accuracy: 0.7974 - val_loss: 1.0173 - val_accuracy: 0.6699\n",
            "Epoch 74/300\n",
            "448/448 [==============================] - 60s 133ms/step - loss: 0.5419 - accuracy: 0.7996 - val_loss: 1.0261 - val_accuracy: 0.6706\n",
            "Epoch 75/300\n",
            "448/448 [==============================] - 60s 135ms/step - loss: 0.5355 - accuracy: 0.8014 - val_loss: 1.0543 - val_accuracy: 0.6738\n",
            "Epoch 76/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.5300 - accuracy: 0.8032 - val_loss: 1.0265 - val_accuracy: 0.6720\n",
            "\n",
            "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0013348387728910893.\n",
            "Epoch 77/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.5233 - accuracy: 0.8078 - val_loss: 1.0252 - val_accuracy: 0.6703\n",
            "Epoch 78/300\n",
            "448/448 [==============================] - 60s 135ms/step - loss: 0.5262 - accuracy: 0.8062 - val_loss: 1.0159 - val_accuracy: 0.6698\n",
            "Epoch 79/300\n",
            "448/448 [==============================] - 61s 136ms/step - loss: 0.5182 - accuracy: 0.8068 - val_loss: 1.0637 - val_accuracy: 0.6716\n",
            "Epoch 80/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.5108 - accuracy: 0.8114 - val_loss: 1.0565 - val_accuracy: 0.6662\n",
            "Epoch 81/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.5112 - accuracy: 0.8106 - val_loss: 1.0534 - val_accuracy: 0.6754\n",
            "\n",
            "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.0010011291014961898.\n",
            "Epoch 82/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.5042 - accuracy: 0.8119 - val_loss: 1.0148 - val_accuracy: 0.6769\n",
            "Epoch 83/300\n",
            "448/448 [==============================] - 61s 136ms/step - loss: 0.5133 - accuracy: 0.8115 - val_loss: 1.0641 - val_accuracy: 0.6687\n",
            "Epoch 84/300\n",
            "448/448 [==============================] - 61s 136ms/step - loss: 0.5055 - accuracy: 0.8142 - val_loss: 1.0487 - val_accuracy: 0.6742\n",
            "Epoch 85/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.5015 - accuracy: 0.8154 - val_loss: 1.0502 - val_accuracy: 0.6729\n",
            "Epoch 86/300\n",
            "448/448 [==============================] - 61s 136ms/step - loss: 0.4998 - accuracy: 0.8152 - val_loss: 1.0254 - val_accuracy: 0.6789\n",
            "\n",
            "Epoch 00086: ReduceLROnPlateau reducing learning rate to 0.0007508468697778881.\n",
            "Epoch 87/300\n",
            "448/448 [==============================] - 61s 136ms/step - loss: 0.4967 - accuracy: 0.8160 - val_loss: 1.0730 - val_accuracy: 0.6715\n",
            "Epoch 88/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.4898 - accuracy: 0.8179 - val_loss: 1.0573 - val_accuracy: 0.6716\n",
            "Epoch 89/300\n",
            "448/448 [==============================] - 62s 137ms/step - loss: 0.4929 - accuracy: 0.8176 - val_loss: 1.0395 - val_accuracy: 0.6789\n",
            "Epoch 90/300\n",
            "448/448 [==============================] - 61s 136ms/step - loss: 0.4938 - accuracy: 0.8196 - val_loss: 1.0561 - val_accuracy: 0.6735\n",
            "Epoch 91/300\n",
            "448/448 [==============================] - 61s 136ms/step - loss: 0.4894 - accuracy: 0.8184 - val_loss: 1.0461 - val_accuracy: 0.6755\n",
            "\n",
            "Epoch 00091: ReduceLROnPlateau reducing learning rate to 0.000563135152333416.\n",
            "Epoch 92/300\n",
            "448/448 [==============================] - 61s 136ms/step - loss: 0.4827 - accuracy: 0.8231 - val_loss: 1.0624 - val_accuracy: 0.6761\n",
            "Epoch 93/300\n",
            "448/448 [==============================] - 61s 136ms/step - loss: 0.4858 - accuracy: 0.8197 - val_loss: 1.0504 - val_accuracy: 0.6776\n",
            "Epoch 94/300\n",
            "448/448 [==============================] - 61s 136ms/step - loss: 0.4799 - accuracy: 0.8219 - val_loss: 1.0862 - val_accuracy: 0.6706\n",
            "Epoch 95/300\n",
            "448/448 [==============================] - 61s 136ms/step - loss: 0.4786 - accuracy: 0.8225 - val_loss: 1.0563 - val_accuracy: 0.6742\n",
            "Epoch 96/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.4800 - accuracy: 0.8248 - val_loss: 1.0586 - val_accuracy: 0.6783\n",
            "\n",
            "Epoch 00096: ReduceLROnPlateau reducing learning rate to 0.0004223513533361256.\n",
            "Epoch 97/300\n",
            "448/448 [==============================] - 60s 135ms/step - loss: 0.4758 - accuracy: 0.8250 - val_loss: 1.0503 - val_accuracy: 0.6773\n",
            "Epoch 98/300\n",
            "448/448 [==============================] - 61s 136ms/step - loss: 0.4758 - accuracy: 0.8240 - val_loss: 1.0564 - val_accuracy: 0.6815\n",
            "Epoch 99/300\n",
            "448/448 [==============================] - 61s 136ms/step - loss: 0.4750 - accuracy: 0.8254 - val_loss: 1.0611 - val_accuracy: 0.6783\n",
            "Epoch 100/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.4765 - accuracy: 0.8240 - val_loss: 1.0434 - val_accuracy: 0.6830\n",
            "Epoch 101/300\n",
            "448/448 [==============================] - 61s 136ms/step - loss: 0.4718 - accuracy: 0.8256 - val_loss: 1.0638 - val_accuracy: 0.6775\n",
            "\n",
            "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.0003167635150020942.\n",
            "Epoch 102/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.4744 - accuracy: 0.8260 - val_loss: 1.0470 - val_accuracy: 0.6766\n",
            "Epoch 103/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.4740 - accuracy: 0.8252 - val_loss: 1.0527 - val_accuracy: 0.6794\n",
            "Epoch 104/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.4748 - accuracy: 0.8263 - val_loss: 1.0481 - val_accuracy: 0.6815\n",
            "Epoch 105/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.4722 - accuracy: 0.8258 - val_loss: 1.0474 - val_accuracy: 0.6790\n",
            "Epoch 106/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.4679 - accuracy: 0.8260 - val_loss: 1.0628 - val_accuracy: 0.6808\n",
            "\n",
            "Epoch 00106: ReduceLROnPlateau reducing learning rate to 0.00023757264716550708.\n",
            "Epoch 107/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.4682 - accuracy: 0.8268 - val_loss: 1.0544 - val_accuracy: 0.6814\n",
            "Epoch 108/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.4703 - accuracy: 0.8264 - val_loss: 1.0637 - val_accuracy: 0.6795\n",
            "Epoch 109/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.4674 - accuracy: 0.8278 - val_loss: 1.0584 - val_accuracy: 0.6801\n",
            "Epoch 110/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.4605 - accuracy: 0.8293 - val_loss: 1.0700 - val_accuracy: 0.6775\n",
            "Epoch 111/300\n",
            "448/448 [==============================] - 60s 135ms/step - loss: 0.4651 - accuracy: 0.8265 - val_loss: 1.0584 - val_accuracy: 0.6839\n",
            "\n",
            "Epoch 00111: ReduceLROnPlateau reducing learning rate to 0.0001781794853741303.\n",
            "Epoch 112/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.4634 - accuracy: 0.8290 - val_loss: 1.0647 - val_accuracy: 0.6790\n",
            "Epoch 113/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.4618 - accuracy: 0.8310 - val_loss: 1.0695 - val_accuracy: 0.6794\n",
            "Epoch 114/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.4649 - accuracy: 0.8258 - val_loss: 1.0639 - val_accuracy: 0.6819\n",
            "Epoch 115/300\n",
            "448/448 [==============================] - 60s 133ms/step - loss: 0.4659 - accuracy: 0.8254 - val_loss: 1.0604 - val_accuracy: 0.6801\n",
            "Epoch 116/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.4668 - accuracy: 0.8290 - val_loss: 1.0604 - val_accuracy: 0.6786\n",
            "\n",
            "Epoch 00116: ReduceLROnPlateau reducing learning rate to 0.00013363461403059773.\n",
            "Epoch 117/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.4619 - accuracy: 0.8318 - val_loss: 1.0663 - val_accuracy: 0.6795\n",
            "Epoch 118/300\n",
            "448/448 [==============================] - 60s 133ms/step - loss: 0.4731 - accuracy: 0.8259 - val_loss: 1.0595 - val_accuracy: 0.6772\n",
            "Epoch 119/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.4606 - accuracy: 0.8308 - val_loss: 1.0660 - val_accuracy: 0.6787\n",
            "Epoch 120/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.4609 - accuracy: 0.8304 - val_loss: 1.0652 - val_accuracy: 0.6775\n",
            "Epoch 121/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.4643 - accuracy: 0.8299 - val_loss: 1.0725 - val_accuracy: 0.6787\n",
            "\n",
            "Epoch 00121: ReduceLROnPlateau reducing learning rate to 0.0001002259632514324.\n",
            "Epoch 122/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.4582 - accuracy: 0.8325 - val_loss: 1.0643 - val_accuracy: 0.6780\n",
            "Epoch 123/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.4664 - accuracy: 0.8272 - val_loss: 1.0635 - val_accuracy: 0.6823\n",
            "Epoch 124/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.4606 - accuracy: 0.8282 - val_loss: 1.0616 - val_accuracy: 0.6790\n",
            "Epoch 125/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.4572 - accuracy: 0.8315 - val_loss: 1.0659 - val_accuracy: 0.6800\n",
            "Epoch 126/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.4636 - accuracy: 0.8281 - val_loss: 1.0690 - val_accuracy: 0.6782\n",
            "\n",
            "Epoch 00126: ReduceLROnPlateau reducing learning rate to 7.516947516705841e-05.\n",
            "Epoch 127/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.4618 - accuracy: 0.8314 - val_loss: 1.0648 - val_accuracy: 0.6775\n",
            "Epoch 128/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.4614 - accuracy: 0.8302 - val_loss: 1.0679 - val_accuracy: 0.6780\n",
            "Epoch 129/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.4593 - accuracy: 0.8320 - val_loss: 1.0693 - val_accuracy: 0.6769\n",
            "Epoch 130/300\n",
            "448/448 [==============================] - 60s 135ms/step - loss: 0.4613 - accuracy: 0.8294 - val_loss: 1.0657 - val_accuracy: 0.6800\n",
            "Epoch 131/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.4614 - accuracy: 0.8311 - val_loss: 1.0700 - val_accuracy: 0.6794\n",
            "\n",
            "Epoch 00131: ReduceLROnPlateau reducing learning rate to 5.6377106375293806e-05.\n",
            "Epoch 132/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.4607 - accuracy: 0.8293 - val_loss: 1.0678 - val_accuracy: 0.6776\n",
            "Epoch 133/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.4597 - accuracy: 0.8288 - val_loss: 1.0658 - val_accuracy: 0.6779\n",
            "Epoch 134/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.4655 - accuracy: 0.8280 - val_loss: 1.0678 - val_accuracy: 0.6773\n",
            "Epoch 135/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.4621 - accuracy: 0.8276 - val_loss: 1.0688 - val_accuracy: 0.6780\n",
            "Epoch 136/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.4581 - accuracy: 0.8287 - val_loss: 1.0667 - val_accuracy: 0.6773\n",
            "\n",
            "Epoch 00136: ReduceLROnPlateau reducing learning rate to 4.2282829781470355e-05.\n",
            "Epoch 137/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.4579 - accuracy: 0.8303 - val_loss: 1.0667 - val_accuracy: 0.6776\n",
            "Epoch 138/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.4587 - accuracy: 0.8298 - val_loss: 1.0690 - val_accuracy: 0.6779\n",
            "Epoch 139/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.4606 - accuracy: 0.8308 - val_loss: 1.0659 - val_accuracy: 0.6775\n",
            "Epoch 140/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.4602 - accuracy: 0.8305 - val_loss: 1.0675 - val_accuracy: 0.6779\n",
            "Epoch 141/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.4585 - accuracy: 0.8300 - val_loss: 1.0671 - val_accuracy: 0.6775\n",
            "\n",
            "Epoch 00141: ReduceLROnPlateau reducing learning rate to 3.171212301822379e-05.\n",
            "Epoch 142/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.4599 - accuracy: 0.8288 - val_loss: 1.0683 - val_accuracy: 0.6780\n",
            "Epoch 143/300\n",
            "448/448 [==============================] - 60s 135ms/step - loss: 0.4603 - accuracy: 0.8277 - val_loss: 1.0675 - val_accuracy: 0.6779\n",
            "Epoch 144/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.4603 - accuracy: 0.8291 - val_loss: 1.0663 - val_accuracy: 0.6776\n",
            "Epoch 145/300\n",
            "448/448 [==============================] - 60s 135ms/step - loss: 0.4603 - accuracy: 0.8308 - val_loss: 1.0674 - val_accuracy: 0.6790\n",
            "Epoch 146/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.4584 - accuracy: 0.8279 - val_loss: 1.0672 - val_accuracy: 0.6775\n",
            "\n",
            "Epoch 00146: ReduceLROnPlateau reducing learning rate to 2.3784092263667844e-05.\n",
            "Epoch 147/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.4619 - accuracy: 0.8303 - val_loss: 1.0656 - val_accuracy: 0.6770\n",
            "Epoch 148/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.4591 - accuracy: 0.8308 - val_loss: 1.0656 - val_accuracy: 0.6780\n",
            "Epoch 149/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.4565 - accuracy: 0.8308 - val_loss: 1.0678 - val_accuracy: 0.6782\n",
            "Epoch 150/300\n",
            "448/448 [==============================] - 60s 133ms/step - loss: 0.4626 - accuracy: 0.8288 - val_loss: 1.0673 - val_accuracy: 0.6776\n",
            "Epoch 151/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.4582 - accuracy: 0.8295 - val_loss: 1.0664 - val_accuracy: 0.6770\n",
            "\n",
            "Epoch 00151: ReduceLROnPlateau reducing learning rate to 1.7838069197750883e-05.\n",
            "Epoch 152/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.4603 - accuracy: 0.8305 - val_loss: 1.0659 - val_accuracy: 0.6779\n",
            "Epoch 153/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.4556 - accuracy: 0.8305 - val_loss: 1.0656 - val_accuracy: 0.6779\n",
            "Epoch 154/300\n",
            "448/448 [==============================] - 60s 134ms/step - loss: 0.4533 - accuracy: 0.8329 - val_loss: 1.0676 - val_accuracy: 0.6784\n",
            "Epoch 155/300\n",
            "448/448 [==============================] - 61s 135ms/step - loss: 0.4601 - accuracy: 0.8315 - val_loss: 1.0673 - val_accuracy: 0.6776\n",
            "Epoch 156/300\n",
            "104/448 [=====>........................] - ETA: 43s - loss: 0.4567 - accuracy: 0.8320"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM2mnyj7oWfN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlIHY8WzL05D"
      },
      "source": [
        "model.save('/content/gdrive/My Drive/emotion_detection/checkpoints/' + 'VGG16-global' + '.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8A3wwkR0qHG",
        "outputId": "04685ef9-57fe-403e-8148-0216f8b88762"
      },
      "source": [
        "model.load_weights(checkpoint_path)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f0def21c090>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1G5vt1zkOMl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "336a85d2-960d-43a6-d1d7-1000bedab1f1"
      },
      "source": [
        "# reset the testing generator and evaluate the network \n",
        "testGen.reset()\n",
        "predIdxs = model.predict(x=testGen,\n",
        "\tsteps=(no_test_files // 64) + 1)\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "print(classification_report(testGen.classes, predIdxs,\n",
        "\ttarget_names=testGen.class_indices.keys()))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.62      0.63      0.63       491\n",
            "     disgust       0.65      0.67      0.66        55\n",
            "        fear       0.58      0.39      0.47       528\n",
            "       happy       0.88      0.91      0.89       879\n",
            "     neutral       0.60      0.77      0.67       626\n",
            "         sad       0.57      0.49      0.53       594\n",
            "    surprise       0.77      0.83      0.80       416\n",
            "\n",
            "    accuracy                           0.69      3589\n",
            "   macro avg       0.67      0.67      0.66      3589\n",
            "weighted avg       0.68      0.69      0.68      3589\n",
            "\n"
          ]
        }
      ]
    }
  ]
}